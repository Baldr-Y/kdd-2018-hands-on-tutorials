{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q-gKT37Didb7"
   },
   "source": [
    "# Setup Notebook\n",
    "\n",
    "Install [ktext](https://github.com/hamelsmu/ktext) and [annoy](https://github.com/spotify/annoy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "E7l80u-0fyHK",
    "outputId": "bd962878-59b3-4ba1-9fdd-852e66a0fc21"
   },
   "outputs": [],
   "source": [
    "# !pip install -q ktext\n",
    "# !pip install -q annoy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from urllib.request import urlopen\n",
    "\n",
    "from annoy import AnnoyIndex\n",
    "from keras import optimizers\n",
    "from keras.layers import Input, Dense, LSTM, GRU, Embedding, Lambda, BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from ktext.preprocess import processor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iZzcs-PDPZqn"
   },
   "source": [
    "# Data sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [English to French](http://www.manythings.org/anki/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!wget http://www.manythings.org/anki/fra-eng.zip\n",
    "!unzip -o fra-eng.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('fra.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "target_docs, source_docs = zip(*[line.strip().split('\\t') for line in lines])\n",
    "target_docs = list(set(target_docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [CoNaLa](https://conala-corpus.github.io/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!wget http://www.phontron.com/download/conala-corpus-v1.1.zip\n",
    "!unzip -o conala-corpus-v1.1.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('conala-corpus/conala-mined.jsonl', 'r') as f:\n",
    "    lines = [json.loads(l) for l in f.readlines()]\n",
    "source_docs = [line['snippet'] for line in lines]\n",
    "target_docs = [line['intent'] for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('conala-corpus/conala-train.json', 'r') as f:\n",
    "    lines = json.load(f)\n",
    "test_docs = [line['rewritten_intent'] for line in lines if line['rewritten_intent']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bw33N_AcPZqp"
   },
   "source": [
    "## GitHub issues data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "GSR2uek3PZqq",
    "outputId": "679c8aab-f736-45b5-bcc9-a5985ba90ddb"
   },
   "outputs": [],
   "source": [
    "issues = pd.read_csv('https://storage.googleapis.com/kubeflow-examples/github-issue-summarization-data/github-issues.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source_docs = list(issues.body)\n",
    "target_docs = list(issues.issue_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AP58__OgPZqt"
   },
   "source": [
    "## Python functions data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "izpU8EXGPZqu",
    "outputId": "749c6f86-cbbd-4e94-fc60-da357ecd44a3"
   },
   "outputs": [],
   "source": [
    "f = urlopen('https://storage.googleapis.com/kubeflow-examples/code_search/data/train.function')\n",
    "source_docs = [x.decode('utf-8') for x in f.readlines()]\n",
    "f = urlopen('https://storage.googleapis.com/kubeflow-examples/code_search/data/train.docstring')\n",
    "target_docs = [x.decode('utf-8') for x in f.readlines()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "Hj1tDqDFPZqx",
    "outputId": "02cc63fd-caca-4d72-8187-ce1cae460349"
   },
   "outputs": [],
   "source": [
    "source_docs = source_docs[:10000]\n",
    "target_docs = target_docs[:10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lxYjchOjPZqz"
   },
   "source": [
    "# 1: Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "COkelzEXPZq0"
   },
   "source": [
    "## Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "uHOMxrONPZq3",
    "outputId": "e01e8ae3-0960-453e-aa9c-87737eeef701"
   },
   "outputs": [],
   "source": [
    "proc = processor(hueristic_pct_padding=.7, keep_n=20000)\n",
    "vecs = proc.fit_transform(target_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "wnjhEa-NPZq6",
    "outputId": "c53c079e-fe55-4ab2-9e25-0baefc19cbb3"
   },
   "outputs": [],
   "source": [
    "vocab_size = max(proc.id2token.keys()) + 1\n",
    "max_length = proc.padding_maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "Ioq7Sd9EPZq8",
    "outputId": "2c1e11a5-b12d-424c-ece2-1cf97c745615"
   },
   "outputs": [],
   "source": [
    "sequences = []\n",
    "for arr in tqdm(vecs):\n",
    "    non_zero = (arr != 0).argmax()\n",
    "    for i in range(non_zero, len(arr)):\n",
    "        sequences.append(arr[:i+1])\n",
    "sequences = pad_sequences(sequences, maxlen=max_length, padding='pre')\n",
    "sequences = np.array(sequences)\n",
    "X, y = sequences[:,:-1], sequences[:,-1]\n",
    "# y = to_categorical(y, num_classes=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "WKW7TCl6PZq_",
    "outputId": "2279454b-3470-470f-8451-5f98d6deacf2"
   },
   "outputs": [],
   "source": [
    "i = Input(shape=(max_length-1,))\n",
    "o = Embedding(vocab_size, 256, input_length=max_length-1)(i)\n",
    "o = LSTM(256, return_sequences=True)(o)\n",
    "last_timestep = Lambda(lambda x: x[:, -1, :])(o)\n",
    "last_timestep = Dense(vocab_size, activation='softmax')(last_timestep)\n",
    "model = Model(i, last_timestep)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 717
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "Psve_dWVPZrB",
    "outputId": "605c91e7-1138-4caf-ec03-069a4320e971"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(X, y, epochs=10, batch_size=64, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cFH1DmGHPZrE"
   },
   "source": [
    "## Generate sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "2R-2I_HRPZrE",
    "outputId": "969f0b6b-bd3d-4fe5-f2aa-267261b5129c"
   },
   "outputs": [],
   "source": [
    "def generate_seq(model, proc, max_length, seed_text, n_words):\n",
    "    in_text = seed_text\n",
    "    for _ in range(n_words):\n",
    "        vec = proc.transform([in_text])[:,1:]\n",
    "        index = np.argmax(model.predict(vec, verbose=0), axis=1)[0]\n",
    "        out_word = ''\n",
    "        if index == 1:\n",
    "            out_word = '_unk_'\n",
    "        else:\n",
    "            out_word = proc.id2token[index]\n",
    "        in_text += ' ' + out_word\n",
    "    return in_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "8wpHSxIOPZrH",
    "outputId": "38e052f0-cdfe-461c-ca0d-9556f6e9a62b"
   },
   "outputs": [],
   "source": [
    "generate_seq(model, proc, max_length, 'there', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zzNZqTqVPZrJ"
   },
   "source": [
    "## Generate embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "Y-Rig9cePZrM",
    "outputId": "77a9944a-b827-490f-a9e3-53c773380ff1"
   },
   "outputs": [],
   "source": [
    "embedding_model = Model(inputs=model.inputs, outputs=model.layers[-3].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "X-FFznLQPZrO",
    "outputId": "5241595b-98c8-433e-9cd2-a22ad6954c92"
   },
   "outputs": [],
   "source": [
    "input_sequence = 'def machine learning'\n",
    "vec = proc.transform([input_sequence])[:,1:]\n",
    "embedding_model.predict(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vecs = proc.transform(test_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_states = embedding_model.predict(vecs[:, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_vecs = np.mean(hidden_states, axis=1)\n",
    "max_vecs = np.max(hidden_states, axis=1)\n",
    "sum_vecs = np.sum(hidden_states, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build vector indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dimension = hidden_states.shape[-1]\n",
    "index = AnnoyIndex(dimension)\n",
    "for i, v in enumerate(sum_vecs):\n",
    "    index.add_item(i, v)\n",
    "index.build(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ids, _ = index.get_nns_by_item(1000, 10, include_distances=True)\n",
    "[test_docs[i] for i in ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_sequence = test_docs[random.randint(0, len(test_docs))]\n",
    "print(input_sequence)\n",
    "\n",
    "vec = proc.transform([input_sequence])[:,1:]\n",
    "vec = np.sum(embedding_model.predict(vec), axis=1)\n",
    "ids, _ = index.get_nns_by_vector(vec.T, 10, include_distances=True)\n",
    "[test_docs[i] for i in ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pnPW20o9PZrR"
   },
   "source": [
    "# 2: Sequence to Sequence Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "s_nE-SeKPZrS",
    "outputId": "25b0b32e-2fdc-4b0b-ab9d-c7003520f00d"
   },
   "outputs": [],
   "source": [
    "source_proc = processor(hueristic_pct_padding=.7, keep_n=20000)\n",
    "source_vecs = source_proc.fit_transform(source_docs)\n",
    "\n",
    "target_proc = processor(append_indicators=True, hueristic_pct_padding=.7, keep_n=14000, padding ='post')\n",
    "target_vecs = target_proc.fit_transform(target_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "3b0wFryNPZrU",
    "outputId": "e45a8a9d-032d-4434-ba46-69cee4d72ca4"
   },
   "outputs": [],
   "source": [
    "encoder_input_data = source_vecs\n",
    "encoder_seq_len = encoder_input_data.shape[1]\n",
    "\n",
    "decoder_input_data = target_vecs[:, :-1]\n",
    "decoder_target_data = target_vecs[:, 1:]\n",
    "\n",
    "num_encoder_tokens = max(source_proc.id2token.keys()) + 1\n",
    "num_decoder_tokens = max(target_proc.id2token.keys()) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FCkBg1_1PZrZ"
   },
   "source": [
    "## Encoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "nThkgdknPZra",
    "outputId": "d9d99e54-4d45-4872-c7a2-c933de5e14ca"
   },
   "outputs": [],
   "source": [
    "word_emb_dim=800\n",
    "hidden_state_dim=1000\n",
    "encoder_seq_len=encoder_seq_len\n",
    "num_encoder_tokens=num_encoder_tokens\n",
    "num_decoder_tokens=num_decoder_tokens\n",
    "\n",
    "encoder_inputs = Input(shape=(encoder_seq_len,), name='Encoder-Input')\n",
    "x = Embedding(num_encoder_tokens, word_emb_dim, name='Body-Word-Embedding', mask_zero=False)(encoder_inputs)\n",
    "x = BatchNormalization(name='Encoder-Batchnorm-1')(x)\n",
    "_, state_h = GRU(hidden_state_dim, return_state=True, name='Encoder-Last-GRU', dropout=.5)(x)\n",
    "encoder_model = Model(inputs=encoder_inputs, outputs=state_h, name='Encoder-Model')\n",
    "seq2seq_encoder_out = encoder_model(encoder_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8PnsgReVPZre"
   },
   "source": [
    "## Decoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "bu-KgmfjPZre",
    "outputId": "ca0de062-3f55-47f2-c2f1-ca39722c00d7"
   },
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(None,), name='Decoder-Input')\n",
    "dec_emb = Embedding(num_decoder_tokens, word_emb_dim, name='Decoder-Word-Embedding', mask_zero=False)(decoder_inputs)\n",
    "dec_bn = BatchNormalization(name='Decoder-Batchnorm-1')(dec_emb)\n",
    "decoder_gru = GRU(hidden_state_dim, return_state=True, return_sequences=True, name='Decoder-GRU', dropout=.5)\n",
    "decoder_gru_output, _ = decoder_gru(dec_bn, initial_state=seq2seq_encoder_out)\n",
    "x = BatchNormalization(name='Decoder-Batchnorm-2')(decoder_gru_output)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax', name='Final-Output-Dense')\n",
    "decoder_outputs = decoder_dense(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WfH-WvGwPZrg"
   },
   "source": [
    "## End to end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "xsNgKYlKPZri",
    "outputId": "3647fd51-06f5-4da3-ea81-37f160b0f22f"
   },
   "outputs": [],
   "source": [
    "seq2seq_model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 578
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "HgUemXCbPZrk",
    "outputId": "001c30a4-891b-4652-a584-252aa96abb46"
   },
   "outputs": [],
   "source": [
    "batch_size = 1100\n",
    "epochs = 16\n",
    "\n",
    "seq2seq_model.compile(optimizer=optimizers.Nadam(lr=0.00005), loss='sparse_categorical_crossentropy')\n",
    "history = seq2seq_model.fit([encoder_input_data, decoder_input_data],\n",
    "                            np.expand_dims(decoder_target_data, -1),\n",
    "                            batch_size=batch_size,\n",
    "                            epochs=epochs,\n",
    "                            validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "UAqk3fIwPZrn",
    "outputId": "d8e93394-1741-4f29-a219-6b34479617af"
   },
   "outputs": [],
   "source": [
    "def extract_decoder_model(model):\n",
    "    latent_dim = model.get_layer('Encoder-Model').output_shape[-1]\n",
    "    decoder_inputs = model.get_layer('Decoder-Input').input\n",
    "    dec_emb = model.get_layer('Decoder-Word-Embedding')(decoder_inputs)\n",
    "    dec_bn = model.get_layer('Decoder-Batchnorm-1')(dec_emb)\n",
    "    gru_inference_state_input = Input(shape=(latent_dim,), name='hidden_state_input')\n",
    "    gru_out, gru_state_out = model.get_layer('Decoder-GRU')([dec_bn, gru_inference_state_input])\n",
    "    dec_bn2 = model.get_layer('Decoder-Batchnorm-2')(gru_out)\n",
    "    dense_out = model.get_layer('Final-Output-Dense')(dec_bn2)\n",
    "    decoder_model = Model([decoder_inputs, gru_inference_state_input], [dense_out, gru_state_out])\n",
    "    return decoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "Xe0_KakGPZrp",
    "outputId": "eeaad795-a14b-4cac-a534-2c8b177004ef"
   },
   "outputs": [],
   "source": [
    "encoder_model = seq2seq_model.get_layer('Encoder-Model')\n",
    "decoder_model = extract_decoder_model(seq2seq_model)\n",
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "JvK1eN9fPZrr",
    "outputId": "916bf747-d2a6-4784-ea7f-e74d203d8dc6"
   },
   "outputs": [],
   "source": [
    "max_len = target_proc.padding_maxlen\n",
    "raw_input_text = source_docs[0]\n",
    "\n",
    "raw_tokenized = source_proc.transform([raw_input_text])\n",
    "encoding = encoder_model.predict(raw_tokenized)\n",
    "original_encoding = encoding\n",
    "state_value = np.array(target_proc.token2id['_start_']).reshape(1, 1)\n",
    "\n",
    "decoded_sentence = []\n",
    "stop_condition = False\n",
    "while not stop_condition:\n",
    "    preds, st = decoder_model.predict([state_value, encoding])\n",
    "    pred_idx = np.argmax(preds[:, :, 2:]) + 2\n",
    "    pred_word_str = target_proc.id2token[pred_idx]\n",
    "\n",
    "    if pred_word_str == '_end_' or len(decoded_sentence) >= max_len:\n",
    "        stop_condition = True\n",
    "        break\n",
    "    decoded_sentence.append(pred_word_str)\n",
    "\n",
    "    # update the decoder for the next word\n",
    "    encoding = st\n",
    "    state_value = np.array(pred_idx).reshape(1, 1)\n",
    "\n",
    "' '.join(decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "1xgPRKJqPZrv"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "Feature Extraction and Summarization with Sequence to Sequence Learning.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
